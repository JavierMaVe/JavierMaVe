# Bash y Scripting para Data Engineering

## Tabla de Contenido

* [1. IntroducciÃ³n: Bash en el Ecosistema de Data Engineering](#1-introducciÃ³n-bash-en-el-ecosistema-de-data-engineering)  
    * [1.1. Â¿QuÃ© es Bash y por quÃ© es crucial para Data Engineers?](#11-quÃ©-es-bash-y-por-quÃ©-es-crucial-para-data-engineers)  
    * [1.2. La Terminal como Herramienta de Trabajo](#12-la-terminal-como-herramienta-de-trabajo)  

* [2. Fundamentos Esenciales de la CLI](#2-fundamentos-esenciales-de-la-cli)  
    * [2.1. NavegaciÃ³n y GestiÃ³n BÃ¡sica del Sistema de Archivos](#21-navegaciÃ³n-y-gestiÃ³n-bÃ¡sica-del-sistema-de-archivos)  
        * (`pwd`, `ls`, `cd`, `mkdir`, `rmdir`, `tree`)  
    * [2.2. Trabajo con Archivos y Directorios (Foco en Datos)](#22-trabajo-con-archivos-y-directorios-foco-en-datos)  
        * (`touch`, `cp`, `mv`, `rm`, `stat`, `du`, `df`)  
    * [2.3. VisualizaciÃ³n de Archivos Grandes](#23-visualizaciÃ³n-de-archivos-grandes)  
        * (`cat`, `less`, `more`, `head`, `tail -f`)  
    * [2.4. Permisos y Propiedad (Importante para Pipelines)](#24-permisos-y-propiedad-importante-para-pipelines)  
        * (`chmod`, `chown`, `ls -l`)  
    * [2.5. Obtener Ayuda (`man`, `--help`)](#25-obtener-ayuda-man---help)  
    * [2.6. Alias, Variables de Entorno y PersonalizaciÃ³n](#26-alias-variables-de-entorno-y-personalizaciÃ³n)  
        * (`alias`, `unalias`, `.bashrc`, `.bash_profile`, `export`)  

* [3. Procesamiento de Datos en la LÃ­nea de Comandos](#3-procesamiento-de-datos-en-la-lÃ­nea-de-comandos)  
    * [3.1. BÃºsqueda y Filtrado de Texto](#31-bÃºsqueda-y-filtrado-de-texto)  
        * [`grep` (con regex bÃ¡sicas)](#grep-con-regex-bÃ¡sicas)  
    * [3.2. ManipulaciÃ³n y TransformaciÃ³n de Texto/Stream](#32-manipulaciÃ³n-y-transformaciÃ³n-de-textostream)  
        * [`sed`](#sed---editor-de-flujo-para-transformaciones)  
        * [`awk`](#awk---procesamiento-avanzado-por-columnas)  
        * [`cut`](#cut---seleccionar-columnas-o-campos)  
        * [`tr`](#tr---traducir-o-eliminar-caracteres)  
    * [3.3. OrdenaciÃ³n y AgregaciÃ³n BÃ¡sica](#33-ordenaciÃ³n-y-agregaciÃ³n-bÃ¡sica)  
        * [`sort`](#sort---ordenar-lÃ­neas)  
        * [`uniq`](#uniq---eliminar-duplicados-y-contar)  
        * [`wc`](#wc---contar-lÃ­neas-palabras-bytes)  
    * [3.4. Trabajo con JSON](#34-trabajo-con-json)  
        * [`jq`](#jq---el-procesador-json-de-lÃ­nea-de-comandos)  
    * [3.5. RedirecciÃ³n de I/O (`>`, `>>`, `<`, `2>`)](#35-redirecciÃ³n-de-io---2)  
    * [3.6. Combinando Herramientas con TuberÃ­as (Pipes `|`)](#36-combinando-herramientas-con-tuberÃ­as-pipes-)  

* [4. Conectividad y Transferencia de Datos](#4-conectividad-y-transferencia-de-datos)  
    * [4.1. ConexiÃ³n Remota](#41-conexiÃ³n-remota)  
        * [`ssh`](#ssh---conexiÃ³n-segura-a-servidores-remotos)  
    * [4.2. Transferencia Segura de Archivos](#42-transferencia-segura-de-archivos)  
        * [`scp`](#scp---copia-segura-simple)  
        * [`rsync`](#rsync---sincronizaciÃ³n-eficiente-de-archivos)  
    * [4.3. Descarga de Datos desde la Web/APIs](#43-descarga-de-datos-desde-la-webapis)  
        * [`curl`](#curl---transferencia-de-datos-con-urls-interacciÃ³n-con-apis)  
        * [`wget`](#wget---descarga-no-interactiva-de-archivos)  

* [5. Scripting Bash para AutomatizaciÃ³n de Tareas](#5-scripting-bash-para-automatizaciÃ³n-de-tareas)  
    * [5.1. CreaciÃ³n y EjecuciÃ³n de Scripts (`#!/bin/bash`, `chmod +x`)](#51-creaciÃ³n-y-ejecuciÃ³n-de-scripts-binbash-chmod-x)  
    * [5.2. Variables, Comillas y SustituciÃ³n de Comandos](#52-variables-comillas-y-sustituciÃ³n-de-comandos)  
    * [5.3. Entrada y Argumentos en Scripts](#53-entrada-y-argumentos-en-scripts)  
        * [5.3.1. Argumentos de Script (`$0`, `$1`, `$@`, `$#`)](#531-argumentos-de-script-0-1-)  
        * [5.3.2. Entrada del Usuario (`read`)](#532-entrada-del-usuario-read) 
    * [5.4. Estructuras Condicionales (`if`, `case`)](#54-estructuras-condicionales-if-case)  
    * [5.5. Bucles (`for`, `while`)](#55-bucles-for-while)  
    * [5.6. Funciones para Reutilizar CÃ³digo](#56-funciones-para-reutilizar-cÃ³digo)  
    * [5.7. GestiÃ³n de Errores y Estado de Salida (`exit`, `$?`, `set -e`, `set -o pipefail`)](#57-gestiÃ³n-de-errores-y-estado-de-salida-exit--set--e-set--o-pipefail)  
        * [Importancia para orquestadores (Airflow, Cron, etc.)](#importancia-para-orquestadores-airflow-cron-etc)  
    * [5.8. Pruebas y Validaciones en Scripts](#58-pruebas-y-validaciones-en-scripts)  

* [6. InteracciÃ³n con Herramientas de Data Engineering](#6-interacciÃ³n-con-herramientas-de-data-engineering)  
    * [6.1. CLIs de Bases de Datos (Ejemplos)](#61-clis-de-bases-de-datos-ejemplos)  
        * (`psql`, `mysql`, `sqlcmd`, etc.)  
    * [6.2. CLIs de Cloud Providers (Ejemplos)](#62-clis-de-cloud-providers-ejemplos)  
        * (`aws cli`, `gcloud`, `az cli`)  
    * [6.3. InteracciÃ³n con Contenedores (Docker/Kubernetes)](#63-interacciÃ³n-con-contenedores-dockerkubernetes)  
        * (`docker exec`, `kubectl cp`, `kubectl logs`)  
    * [6.4. Control de Versiones con Git](#64-control-de-versiones-con-git)  
        * (Comandos bÃ¡sicos de `git` desde la CLI)  
    * [6.5. Lanzar Scripts de Python desde Bash](#65-lanzar-scripts-de-python-desde-bash)  
        * (`python script.py`, `venv`, logs, errores)  

* [7. TÃ³picos Adicionales y Buenas PrÃ¡cticas](#7-tÃ³picos-adicionales-y-buenas-prÃ¡cticas)  
    * [7.1. GestiÃ³n de Variables de Entorno y Secretos](#71-gestiÃ³n-de-variables-de-entorno-y-secretos)  
    * [7.2. CompresiÃ³n y Archivado (`tar`, `gzip`, `zip`)](#72-compresiÃ³n-y-archivado-tar-gzip-zip)  
    * [7.3. ProgramaciÃ³n de Tareas con `cron`](#73-programaciÃ³n-de-tareas-con-cron)  
    * [7.4. Debugging de Scripts (`set -x`, `echo`)](#74-debugging-de-scripts-set--x-echo)  
    * [7.5. Estilo y Legibilidad en Scripts](#75-estilo-y-legibilidad-en-scripts)  
    * [7.6. Herramientas CLI Ãºtiles para Data Engineers](#76-herramientas-cli-Ãºtiles-para-data-engineers)  
        * (`htop`, `watch`, `pv`, `parallel`, `fd`, `ripgrep`)  

* [8. Ejemplos de Scripts para Data Engineering](#8-ejemplos-de-scripts-para-data-engineering)  
    * [8.1. Script para Descargar y Preprocesar Logs](#81-script-para-descargar-y-preprocesar-logs)  
    * [8.2. Script para Mover Datos Procesados a Almacenamiento Cloud](#82-script-para-mover-datos-procesados-a-almacenamiento-cloud)  
    * [8.3. Script Wrapper para Ejecutar un Proceso SQL/Python](#83-script-wrapper-para-ejecutar-un-proceso-sqlpython)  

* [9. Recursos](#9-recursos)

# 1. IntroducciÃ³n: Bash en el Ecosistema de Data Engineering

Bash (Bourne Again SHell) es uno de los intÃ©rpretes de lÃ­nea de comandos mÃ¡s utilizados en sistemas Unix y Linux. En el contexto del Data Engineering, Bash no solo es una herramienta Ãºtil, sino muchas veces esencial. Permite automatizar tareas, procesar archivos, interactuar con sistemas remotos y coordinar flujos de trabajo entre diferentes herramientas.



---

## 1.1. Â¿QuÃ© es Bash y por quÃ© es crucial para Data Engineers?

Bash es una shell de comandos que permite al usuario comunicarse con el sistema operativo mediante texto. Si bien Bash se puede usar de forma interactiva, su verdadero poder estÃ¡ en los **scripts**: pequeÃ±os programas escritos en Bash que automatizan tareas repetitivas o complejas.

### Razones por las que Bash es fundamental en Data Engineering:

- ðŸ” **AutomatizaciÃ³n de tareas rutinarias** como mover archivos, lanzar scripts Python o descargar datos.
- ðŸ“‚ **ManipulaciÃ³n eficiente de archivos y directorios**, algo frecuente al trabajar con datos crudos, logs o archivos CSV.
- ðŸ“¡ **ConexiÃ³n remota y transferencia de archivos** a travÃ©s de `ssh`, `scp` o `rsync`.
- ðŸ§© **IntegraciÃ³n con otras herramientas** como `cron`, Docker, gestores de bases de datos o cloud CLIs (`aws`, `gcloud`, etc.).
- ðŸ§ª **ValidaciÃ³n y preprocesamiento de datos** directamente desde la lÃ­nea de comandos.

Incluso si el nÃºcleo del procesamiento de datos estÃ¡ en Python, Spark o SQL, Bash actÃºa como el **pegamento que conecta todo el pipeline**.

---

## 1.2. La Terminal como Herramienta de Trabajo

La **terminal** (o consola) es la interfaz a travÃ©s de la cual interactuamos con Bash. Usar eficientemente la terminal te permite:

- Navegar rÃ¡pidamente por carpetas y archivos.
- Ejecutar comandos del sistema.
- Visualizar logs en tiempo real.
- Componer comandos poderosos con tuberÃ­as (`|`) y redirecciones (`>`).

Como Data Engineer, dominar la terminal es una ventaja porque:

- Puedes trabajar en servidores remotos donde no hay interfaces grÃ¡ficas.
- Permite usar herramientas CLI como `jq`, `awk`, `curl`, `psql`, etc.
- Es indispensable para el debugging de scripts, servicios o ETL jobs.

---

# 2. Fundamentos Esenciales de la CLI

Antes de automatizar tareas o procesar datos desde la terminal, necesitas dominar lo bÃ¡sico: navegar por el sistema de archivos, gestionar archivos y carpetas, consultar informaciÃ³n Ãºtil y personalizar tu entorno de trabajo.

---

## 2.1. NavegaciÃ³n y GestiÃ³n BÃ¡sica del Sistema de Archivos

En Bash, puedes moverte entre carpetas y explorar tu sistema de archivos rÃ¡pidamente con unos pocos comandos:

| Comando      | DescripciÃ³n |
|--------------|-------------|
| `pwd`        | Muestra la ruta del directorio actual (*print working directory*). |
| `ls`         | Lista el contenido de un directorio. Usa `ls -l` para una vista detallada y `ls -a` para incluir archivos ocultos. |
| `cd`         | Cambia de directorio. Ejemplo: `cd /var/log` o `cd ..` para subir un nivel. |
| `mkdir`      | Crea una carpeta. Ejemplo: `mkdir datos` |
| `rmdir`      | Elimina un directorio vacÃ­o. Para carpetas con contenido, usa `rm -r`. |
| `tree`       | Muestra la estructura de carpetas en forma de Ã¡rbol (puede requerir instalaciÃ³n previa). |
---

## 2.2. Trabajo con Archivos y Directorios

Manipular archivos es una tarea central en pipelines de datos. Estos comandos te permiten crearlos, copiarlos, moverlos, renombrarlos y analizarlos:

| Comando      | DescripciÃ³n |
|--------------|-------------|
| `touch`      | Crea un archivo vacÃ­o. TambiÃ©n actualiza la fecha de modificaciÃ³n si ya existe. |
| `cp`         | Copia archivos o carpetas. Usa `cp -r` para copiar directorios recursivamente. |
| `mv`         | Mueve o renombra archivos. Ejemplo: `mv archivo.csv backup/archivo_2025.csv` |
| `rm`         | Elimina archivos. Usa con cuidado. `rm -r` para eliminar directorios con contenido. |
| `stat`       | Muestra metadatos del archivo: tamaÃ±o, permisos, fechas, etc. |
| `du -sh`     | Muestra el tamaÃ±o de una carpeta o archivo. Muy Ãºtil para logs o dumps de datos. |
| `df -h`      | Muestra el uso del sistema de archivos (espacio libre/disco ocupado). |
---

## 2.3. VisualizaciÃ³n de Archivos Grandes

Muchos archivos de datos (CSV, logs, JSON) pueden ser grandes. Estos comandos permiten inspeccionarlos sin sobrecargar la terminal:

| Comando      | DescripciÃ³n |
|--------------|-------------|
| `cat`        | Muestra todo el contenido del archivo (solo recomendable para archivos pequeÃ±os). |
| `less`       | Navega por el archivo pÃ¡gina a pÃ¡gina. Usa `q` para salir. |
| `more`       | Similar a `less`, pero menos flexible. |
| `head`       | Muestra las primeras lÃ­neas. Ejemplo: `head -n 20 archivo.log` |
| `tail`       | Muestra las Ãºltimas lÃ­neas. |
| `tail -f`    | Sigue el crecimiento de un archivo en tiempo real (Ãºtil para ver logs en ejecuciÃ³n). |

---

## 2.4. Permisos y Propiedad (Importante para Pipelines)

Cuando trabajas con scripts o pipelines, es clave entender los permisos de los archivos y carpetas:

| Comando      | DescripciÃ³n |
|--------------|-------------|
| `ls -l`      | Lista archivos con detalles de permisos, propietario y grupo. |
| `chmod`      | Cambia los permisos. Ejemplo: `chmod +x script.sh` para hacerlo ejecutable. |
| `chown`      | Cambia el propietario de un archivo. Ãštil al mover archivos entre usuarios o contenedores. |
---

## 2.5. Obtener Ayuda (`man`, `--help`)

Bash tiene ayuda integrada. Puedes consultar la documentaciÃ³n oficial de cualquier comando:

| Comando      | DescripciÃ³n |
|--------------|-------------|
| `man nombre_comando` | Abre el manual del comando. Ejemplo: `man grep` |
| `nombre_comando --help` | Muestra ayuda rÃ¡pida. Ejemplo: `ls --help` |
---

## 2.6. Alias, Variables de Entorno y PersonalizaciÃ³n

Una de las ventajas de Bash es que puedes personalizarlo para que se adapte a tu flujo de trabajo. Esto incluye crear alias para comandos que usas frecuentemente, definir variables de entorno, y modificar archivos de configuraciÃ³n como `.bashrc` o `.bash_profile`.

---

### ðŸ” Alias

Un **alias** es una forma de acortar o modificar un comando para hacerlo mÃ¡s rÃ¡pido de escribir o mÃ¡s funcional por defecto.


#### ðŸ‘‰ Ver todos los alias definidos:

```bash
alias
```
#### ðŸ“Œ Ejemplos comunes:

```bash
alias ll='ls -lh --color=auto'
alias gs='git status'
alias py='python3'
alias cls='clear'
```
#### ðŸ”¨ Para crear un alias:

```bash
alias nombre='comando'
```

#### âŒ Eliminar un alias temporalmente:

```bash
unalias ll
```

#### âœ… Hacer que un alias sea permanente:

Agrega el alias en tu archivo `~/.bashrc` o `~/.bash_profile`:

Una vez guardado, tenemos que recargar con source

```bash
echo "alias ll='ls -lh --color=auto'" >> ~/.bashrc
source ~/.bashrc
```
#### ðŸ’» Ejecutar un comando sin alias

```bash
\ls
command ls
/bin/ls
```

#### ðŸ’» Notas

Un alias no estarÃ¡ disponible en otra ventana de la terminal, a no ser, que se haya guardado en bashrc y recargado con source.

Si creamos un alias con comillas dobles, si cambiamos una variable, no le afectarÃ¡ al alias

```bash
nombre="Juan"
alias saludo="echo Hola $nombre"
nomber="Ana"
saludo # La salida seguirÃ¡ siendo Hola Juan
```
Si creamos un alias con comillas simples, si cambiamos una variable, esta afectarÃ¡ al alias

```bash
nombre="Juan"
alias saludo='echo Hola $nombre'
nomber="Ana"
saludo # La salida serÃ¡ ahora Hola Ana
```

---

### ðŸŒ Variables de Entorno

Las **variables de entorno** almacenan informaciÃ³n usada por Bash y otros programas. Son especialmente Ãºtiles para rutas de datos, tokens, claves, o configuraciones que necesitas reutilizar.

#### ðŸ“Œ Ejemplo:

```bash
export DATA_PATH="/home/usuario/data"
echo $DATA_PATH
```

Puedes usar `$DATA_PATH` en scripts, comandos y otros scripts como si fuera una constante.

#### âœ… Hacerlas permanentes:

Agrega la lÃ­nea al final de tu `~/.bashrc` o `~/.bash_profile`:

```bash
export API_KEY="tu_token_secreto"
```

#### ðŸ”Ž Ver todas las variables de entorno activas:

```bash
printenv
```

---

### ðŸ›  Archivos de configuraciÃ³n: `.bashrc` y `.bash_profile`

| Archivo           | PropÃ³sito principal |
|-------------------|---------------------|
| `~/.bashrc`       | Se ejecuta en cada sesiÃ³n interactiva (cuando abres una terminal). AquÃ­ van la mayorÃ­a de tus alias y funciones. |
| `~/.bash_profile` | Se ejecuta una vez al inicio de la sesiÃ³n de login. A menudo carga `~/.bashrc`. |
---
# 3. Procesamiento de Datos en la LÃ­nea de Comandos

Uno de los superpoderes de Bash es la capacidad de procesar datos directamente desde la terminal, sin necesidad de scripts complejos ni lenguajes externos. Con las herramientas adecuadas, puedes filtrar, transformar, ordenar, combinar y preparar datos desde archivos de texto, logs o salidas de comandos.

---

## 3.1. BÃºsqueda y Filtrado de Texto

### `grep` (con regex bÃ¡sicas)

`grep` permite buscar patrones de texto dentro de archivos o flujos. Muy Ãºtil para filtrar logs, buscar errores o localizar lÃ­neas especÃ­ficas en grandes volÃºmenes de texto.

#### ðŸ“Œ Ejemplos:

```bash
grep "ERROR" logs.txt
grep -i "usuario" usuarios.csv        # Ignora mayÃºsculas/minÃºsculas
grep -v "DEBUG" logs.txt              # Excluye lÃ­neas con DEBUG
grep "^2025" fechas.txt               # LÃ­neas que comienzan con 2025
grep -r "pipeline" ./proyectos        # BÃºsqueda recursiva
```

#### ðŸ§  Ãštil para:
- Extraer lÃ­neas relevantes de logs
- Filtrar grandes volÃºmenes de datos
- Preprocesar archivos antes de analizarlos con Python

---

## 3.2. ManipulaciÃ³n y TransformaciÃ³n de Texto/Stream

Las herramientas de esta secciÃ³n te permiten editar, modificar o seleccionar partes especÃ­ficas de un flujo de texto o archivo.

### `sed` â€“ Editor de flujo para transformaciones

`sed` es un editor de texto no interactivo. Sirve para reemplazos, inserciones, borrado de lÃ­neas, entre otros.

#### ðŸ“Œ Ejemplos:

```bash
sed 's/foo/bar/g' archivo.txt              # Reemplaza todas las apariciones de "foo" por "bar"
sed -n '10,20p' archivo.txt                # Muestra lÃ­neas 10 a 20
sed '/^#/d' archivo.conf                   # Elimina lÃ­neas que comienzan con #
```

### `awk` â€“ Procesamiento avanzado por columnas

`awk` permite operar sobre archivos columna por columna, como si fueran tablas.

#### ðŸ“Œ Ejemplos:

```bash
awk -F',' '{print $1, $3}' datos.csv       # Imprime columna 1 y 3 (separadas por coma)
awk '{suma += $2} END {print suma}' file   # Suma los valores de la segunda columna
awk '$3 > 100 {print $1, $3}' archivo.txt  # Filtra filas donde la columna 3 es mayor a 100
```

### `cut` â€“ Seleccionar columnas o campos

Extrae por posiciÃ³n o delimitador.

#### ðŸ“Œ Ejemplos:

```bash
cut -d',' -f1,3 usuarios.csv               # Extrae columnas 1 y 3 separadas por coma
cut -c1-10 archivo.txt                     # Extrae los primeros 10 caracteres de cada lÃ­nea
```

### `tr` â€“ Traducir o eliminar caracteres

`tr` se usa para reemplazar o eliminar caracteres.

#### ðŸ“Œ Ejemplos:

```bash
tr '[:lower:]' '[:upper:]' < archivo.txt  # Convierte a mayÃºsculas
tr -d '\r' < win.txt > unix.txt           # Elimina retornos de carro (convertir formato Windows a Unix)
```

---

## 3.3. OrdenaciÃ³n y AgregaciÃ³n BÃ¡sica

### `sort` â€“ Ordenar lÃ­neas

#### ðŸ“Œ Ejemplos:

```bash
sort archivo.txt                          # Orden alfabÃ©tico
sort -n valores.txt                       # Orden numÃ©rico
sort -r archivo.txt                       # Orden inverso
```

### `uniq` â€“ Eliminar duplicados y contar ocurrencias

Debe combinarse con `sort` para funcionar correctamente (espera lÃ­neas duplicadas consecutivas).

#### ðŸ“Œ Ejemplos:

```bash
sort archivo.txt | uniq                   # Elimina duplicados
sort archivo.txt | uniq -c                # Cuenta repeticiones
```

### `wc` â€“ Contar lÃ­neas, palabras o bytes

#### ðŸ“Œ Ejemplos:

```bash
wc -l archivo.txt                         # Cantidad de lÃ­neas
wc -w archivo.txt                         # Cantidad de palabras
wc -c archivo.txt                         # Cantidad de bytes
```

---

## 3.4. Trabajo con JSON

### `jq` â€“ El procesador JSON de lÃ­nea de comandos

`jq` permite leer, formatear, filtrar y transformar datos JSON desde la terminal.

#### ðŸ“Œ Ejemplos:

```bash
jq '.' datos.json                         # Formatear y mostrar
jq '.usuarios[].nombre' datos.json        # Obtener nombres dentro de un array
jq 'map(select(.activo == true))' usuarios.json
```

#### ðŸ§  Muy Ãºtil para:
- Inspeccionar respuestas de APIs
- Filtrar logs en formato JSON
- Automatizar procesamiento de estructuras complejas

---

## 3.5. RedirecciÃ³n de I/O (`>`, `>>`, `<`, `2>`)

En Bash, puedes redirigir entradas y salidas fÃ¡cilmente:

| SÃ­mbolo | Significado |
|--------|-------------|
| `>`    | Redirige la salida (sobrescribe archivo) |
| `>>`   | Redirige la salida (agrega al archivo) |
| `<`    | Usa un archivo como entrada |
| `2>`   | Redirige errores (stderr) |

#### ðŸ“Œ Ejemplos:

```bash
echo "Hola mundo" > mensaje.txt            # Crea o sobrescribe
echo "Otra lÃ­nea" >> mensaje.txt           # Agrega al final
sort archivo.txt > salida.txt              # Guarda salida ordenada
comando < entrada.txt                      # Usa archivo como entrada
comando 2> errores.log                     # Guarda errores en archivo
```

---

## 3.6. Combinando Herramientas con TuberÃ­as (Pipes `|`)

El operador `|` permite encadenar comandos: la salida de uno se convierte en la entrada del siguiente.

#### ðŸ“Œ Ejemplo clÃ¡sico:

```bash
cat logs.txt | grep "ERROR" | cut -d' ' -f1 | sort | uniq -c | sort -nr
```

Este comando:
1. Filtra lÃ­neas con "ERROR".
2. Extrae el primer campo (por ejemplo, una fecha).
3. Cuenta cuÃ¡ntas veces ocurre cada fecha.
4. Ordena los resultados de mayor a menor.

#### ðŸ§  ComposiciÃ³n de herramientas:

Combinar `grep`, `awk`, `cut`, `jq`, `sort`, `uniq`, `head`, `tail` permite procesar datos complejos sin salir de Bash. Esto es ideal para validaciones rÃ¡pidas, exploraciÃ³n de datos o preprocesamiento en pipelines.

---

# 4. Conectividad y Transferencia de Datos

En Data Engineering, muchas veces necesitas conectarte a servidores remotos, mover archivos entre mÃ¡quinas, descargar datasets desde APIs o pÃ¡ginas web, y sincronizar contenido entre entornos. Bash ofrece herramientas muy potentes y seguras para todas estas tareas, que puedes usar directamente desde la terminal.

---

## 4.1. ConexiÃ³n Remota

### `ssh` â€“ ConexiÃ³n segura a servidores remotos

`ssh` (Secure Shell) permite conectarse de forma segura a otro equipo o servidor a travÃ©s de la red. Es una herramienta esencial para trabajar con servidores Linux, entornos cloud y clusters de procesamiento de datos.

#### ðŸ“Œ Ejemplos bÃ¡sicos:

```bash
ssh usuario@192.168.1.100
ssh usuario@mi-servidor.com
```

#### ðŸ” ConexiÃ³n con clave privada:

```bash
ssh -i ~/.ssh/id_rsa usuario@mi-servidor.com
```

#### âš™ï¸ Opciones Ãºtiles:

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `-p 2222` | Especificar un puerto diferente (por defecto es el 22) |
| `-T` | No asigna una pseudo-terminal (ideal para automatizaciÃ³n) |
| `-L` | Redireccionamiento de puertos (tÃºneles SSH) |

#### ðŸ§  Casos de uso:

- Ejecutar scripts en servidores remotos
- Acceder a logs o bases de datos
- Configurar y controlar servicios ETL desplegados en producciÃ³n

---

## 4.2. Transferencia Segura de Archivos

### `scp` â€“ Copia segura simple

`scp` (Secure Copy) permite copiar archivos entre mÃ¡quinas a travÃ©s de SSH. Es simple, rÃ¡pido y ampliamente soportado.

#### ðŸ“Œ Ejemplos:

```bash
scp archivo.csv usuario@servidor:/home/usuario/datos/
scp usuario@servidor:/var/log/app.log ./logs/
```

#### âš™ï¸ Opciones Ãºtiles:

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `-r` | Copia directorios recursivamente |
| `-P` | Especifica el puerto (ej. `-P 2222`) |
| `-i` | Usa una clave privada especÃ­fica |

---

### `rsync` â€“ SincronizaciÃ³n eficiente de archivos

`rsync` es ideal para sincronizar archivos o carpetas entre sistemas. Solo transfiere los cambios, por lo que es mÃ¡s eficiente que `scp`.

#### ðŸ“Œ Ejemplos:

```bash
rsync -avh datos/ usuario@servidor:/home/usuario/datos/
rsync -azP ./proyecto usuario@servidor:/deploy
```

#### âš™ï¸ Opciones recomendadas:

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `-a` | Modo archivo (mantiene permisos, fechas, etc.) |
| `-v` | Muestra salida detallada (verbose) |
| `-z` | Comprime durante la transferencia |
| `-P` | Muestra progreso y permite continuar descargas interrumpidas |

#### ðŸ§  Casos de uso:

- Mover backups de datos entre servidores
- Sincronizar directorios locales con entornos cloud
- Automatizar cargas de datos entre equipos de trabajo

---

## 4.3. Descarga de Datos desde la Web/APIs

### `curl` â€“ Transferencia de datos con URLs e interacciÃ³n con APIs

`curl` es una herramienta versÃ¡til que permite realizar peticiones HTTP, descargar archivos, enviar datos a APIs, autenticarse y mÃ¡s.

#### ðŸ“Œ Ejemplos bÃ¡sicos:

```bash
curl -O https://datos.gob.es/archivo.csv       # Descarga archivo
curl https://api.datos.com/info                # Muestra respuesta en pantalla
```

#### ðŸ›  AutenticaciÃ³n y Headers:

```bash
curl -H "Authorization: Bearer $TOKEN" https://api.datos.com/data
curl -X POST -d '{"nombre":"Juan"}' -H "Content-Type: application/json" https://api.app.com/crear
```

#### âš™ï¸ Opciones comunes:

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `-O` | Guarda el archivo con el mismo nombre |
| `-o archivo.ext` | Guarda con nombre especÃ­fico |
| `-H` | Agrega un encabezado HTTP |
| `-d` | EnvÃ­a datos en el cuerpo del request |
| `-X` | Especifica mÃ©todo HTTP (`GET`, `POST`, etc.) |

---

### `wget` â€“ Descarga no interactiva de archivos

`wget` es ideal para descargar archivos de forma automÃ¡tica o en segundo plano. Funciona muy bien con enlaces directos.

#### ðŸ“Œ Ejemplos:

```bash
wget https://example.com/dataset.zip
wget -c https://example.com/bigfile.zip       # ContinÃºa descarga interrumpida
wget -r -np -nH --cut-dirs=1 -R index.html https://example.com/data/
```

#### âš™ï¸ Opciones recomendadas:

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `-c` | Reanuda descargas |
| `-r` | Descarga recursiva |
| `-np` | No seguir enlaces a carpetas superiores |
| `--limit-rate=200k` | Limita la velocidad de descarga |

---

# 5. Scripting Bash para AutomatizaciÃ³n de Tareas

Los scripts en Bash son la forma mÃ¡s comÃºn y eficiente de automatizar tareas repetitivas en sistemas Unix/Linux. Desde mover archivos hasta ejecutar pipelines de datos, Bash permite crear flujos lÃ³gicos robustos y reutilizables con muy poco cÃ³digo.

---

## 5.1. CreaciÃ³n y EjecuciÃ³n de Scripts (`#!/bin/bash`, `chmod +x`)

Un script Bash es simplemente un archivo de texto que contiene comandos que se ejecutarÃ­an normalmente en la terminal.

### ðŸ“Œ Ejemplo bÃ¡sico:

```bash
#!/bin/bash
echo "Hola, mundo"
```

### âœ… Pasos para ejecutarlo:

1. Crear el archivo, por ejemplo `script.sh`
2. Darle permisos de ejecuciÃ³n:

```bash
chmod +x script.sh
```

3. Ejecutarlo:

```bash
./script.sh
```

> La lÃ­nea `#!/bin/bash` se conoce como *shebang* y le dice al sistema que debe ejecutar el script usando Bash.

---

## 5.2. Variables, Comillas y SustituciÃ³n de Comandos

### ðŸ“Œ DeclaraciÃ³n de variables:

```bash
nombre="Juan"
echo "Hola $nombre"
```

### ðŸ“Œ Uso de comillas:

- Comillas dobles (`"`): permiten evaluar variables.
- Comillas simples (`'`): muestran el contenido literal.

```bash
echo "Hola $nombre"   # Hola Juan
echo 'Hola $nombre'   # Hola $nombre
```

### ðŸ“Œ SustituciÃ³n de comandos:

```bash
fecha=$(date)
echo "Hoy es $fecha"
```

---

### 5.3. Entrada y Argumentos en Scripts

En Bash, los scripts pueden recibir **argumentos desde la lÃ­nea de comandos** y tambiÃ©n **solicitar entrada del usuario de forma interactiva**. Ambas formas son fundamentales para crear scripts dinÃ¡micos, reutilizables y mÃ¡s flexibles.

---

#### 5.3.1. Argumentos de Script (`$0`, `$1`, `$@`, `$#`)

Cuando ejecutas un script y le pasas parÃ¡metros, Bash los asigna a **parÃ¡metros posicionales** automÃ¡ticamente:

```bash
#!/bin/bash

echo "Nombre del script: $0"
echo "Primer argumento: $1"
echo "Segundo argumento: $2"
echo "Todos: $@"
echo "Cantidad de argumentos: $#"
```

##### ðŸ” Ejemplo de ejecuciÃ³n:

```bash
./script.sh archivo.csv 2025
```

**Resultado:**

```
Nombre del script: ./script.sh
Primer argumento: archivo.csv
Segundo argumento: 2025
Todos: archivo.csv 2025
Cantidad de argumentos: 2
```

##### ðŸ§  DescripciÃ³n rÃ¡pida:

| Variable | Significado |
|----------|-------------|
| `$0`     | Nombre del script |
| `$1`     | Primer argumento |
| `$2`     | Segundo argumento |
| `$@`     | Todos los argumentos, separados correctamente |
| `$*`     | Todos los argumentos como una sola cadena |
| `$#`     | NÃºmero total de argumentos |

##### ðŸ“Œ Diferencia entre `$@` y `$*`:

```bash
for arg in "$@"; do
  echo "arg: $arg"
done
```

Este ejemplo **respeta los espacios** en los argumentos.

```bash
for arg in "$*"; do
  echo "arg: $arg"
done
```

Este los trata como una sola cadena, lo que puede generar errores si hay espacios.

---

#### 5.3.2. Entrada del Usuario (`read`)

Bash tambiÃ©n permite **solicitar valores directamente al usuario** con el comando `read`.

##### ðŸ“Œ Ejemplo bÃ¡sico:

El flag -p en el comando read sirve para mostrar un mensaje o prompt antes de leer la entrada del usuario.

```bash
#!/bin/bash

read -p "Â¿CÃ³mo te llamas? " nombre
echo "Hola, $nombre"
```

Cuando se ejecuta:

```
Â¿Como te llamas? Ana
Hola, Ana
```

##### âœ… Variantes Ãºtiles:

El flag -s en read es sÃºper Ãºtil para ocultar la entrada del usuario (como cuando se escribe una contraseÃ±a).

```bash
read -s -p "Introduce tu contraseÃ±a: " pass   # Entrada oculta
read -n 1 -p "Â¿Deseas continuar? [s/n] " opt   # Solo una tecla
```

> Usa `read` para configuraciones interactivas, confirmaciones, o cuando no quieras pasar parÃ¡metros al iniciar el script.

---

ðŸ” Combinando ambos (argumentos + read) puedes crear scripts muy flexibles. Por ejemplo:

```bash
#!/bin/bash

if [ -z "$1" ]; then
    read -p "Introduce tu nombre: " nombre
else
    nombre=$1
fi

echo "Bienvenido, $nombre"
```
### ðŸ“˜ Flags del comando `read` en Bash

| Flag     | DescripciÃ³n                                                                 | Ejemplo                                              |
|----------|-----------------------------------------------------------------------------|------------------------------------------------------|
| `-p`     | Muestra un **mensaje (prompt)** antes de leer                              | `read -p "Tu nombre: " nombre`                      |
| `-s`     | **Oculta** la entrada (ideal para contraseÃ±as)                             | `read -s -p "ContraseÃ±a: " pass`                    |
| `-n N`   | Lee **solo N caracteres**, sin esperar Enter                               | `read -n 1 -p "Â¿Continuar? [s/n] " opcion`          |
| `-t N`   | **Espera N segundos** antes de cancelar el `read`                          | `read -t 5 -p "Ingresa valor: " valor`              |
| `-e`     | Habilita **ediciÃ³n de lÃ­nea e historial** (como la terminal)               | `read -e -p "Ruta del archivo: " ruta`              |
| `-r`     | No interpreta **caracteres de escape** (`\\`, `\\n`, etc.)                 | `read -r linea`                                     |
| `-a`     | Guarda la entrada como un **array**, separando por espacios                | `read -a palabras`                                  |
| `-d X`   | Lee hasta el **carÃ¡cter delimitador X** (en vez de Enter)                  | `read -d ':' variable`                              |

> ðŸ’¡ Puedes combinar varios flags:  
> Ejemplo: `read -s -n 1 -p "Presiona una tecla..." tecla`


---

## 5.4. Estructuras Condicionales (`if`, `case`)

### `if` bÃ¡sico:

```bash
if [ -f archivo.txt ]; then
  echo "El archivo existe"
else
  echo "No existe"
fi
```

### `case` para mÃºltiples opciones:

```bash
case $1 in
  start)
    echo "Iniciando..."
    ;;
  stop)
    echo "Deteniendo..."
    ;;
  *)
    echo "Uso: $0 {start|stop}"
    ;;
esac
```

---

## 5.5. Bucles (`for`, `while`)

### `for`:

```bash
for archivo in *.csv; do
  echo "Procesando $archivo"
done
```

### `while`:

```bash
contador=1
while [ $contador -le 5 ]; do
  echo "IteraciÃ³n $contador"
  ((contador++))
done
```

---

## 5.6. Funciones para Reutilizar CÃ³digo

Definir funciones permite reutilizar bloques de cÃ³digo y estructurar mejor los scripts.

```bash
saludar() {
  echo "Hola $1"
}

saludar "Ana"
```

Puedes pasar parÃ¡metros, retornar cÃ³digos de estado y usar funciones como cualquier otro comando.

---

## 5.7. GestiÃ³n de Errores y Estado de Salida (`exit`, `$?`, `set -e`, `set -o pipefail`)

### ðŸ“Œ Salida y cÃ³digos de error:

```bash
exit 0  # Ã‰xito
exit 1  # Error
```

Ver el estado de salida del Ãºltimo comando:

```bash
echo $?
```

### ðŸ“Œ Fallar al primer error:

```bash
set -e
```

### ðŸ“Œ Asegurar propagaciÃ³n de errores en pipes:

```bash
set -o pipefail
```

> Muy importante en entornos de producciÃ³n y cuando se integran con orquestadores como **Airflow**, **Luigi**, **Cron**, etc. Evita que errores pasen desapercibidos.

---

## 5.8. Pruebas y Validaciones en Scripts

Validar condiciones antes de ejecutar operaciones es fundamental.

### ðŸ“Œ Validaciones comunes:

```bash
# Verificar que un archivo existe
if [ ! -f datos.csv ]; then
  echo "El archivo datos.csv no existe"
  exit 1
fi

# Verificar que una variable no estÃ© vacÃ­a
if [ -z "$API_KEY" ]; then
  echo "Falta la API_KEY"
  exit 1
fi
```

### ðŸ“Œ Uso de `test`:

```bash
test -d carpeta && echo "La carpeta existe"
```

---

# 6. InteracciÃ³n con Herramientas de Data Engineering

El trabajo de un Data Engineer implica usar una gran variedad de herramientas, muchas de las cuales ofrecen interfaces de lÃ­nea de comandos (CLI). Integrarlas con Bash permite automatizar flujos complejos, gestionar recursos y lanzar procesos de datos de forma eficiente.

---

## 6.1. CLIs de Bases de Datos (Ejemplos)

### `psql` â€“ PostgreSQL

```bash
psql -U usuario -d basedatos -c "SELECT COUNT(*) FROM usuarios;"
```

AutenticaciÃ³n por variables:

```bash
PGPASSWORD=clave psql -U usuario -h host -d basedatos -c "SELECT version();"
```

### `mysql` â€“ MySQL/MariaDB

```bash
mysql -u root -p
mysql -u usuario -p basedatos < consulta.sql
```

### `sqlcmd` â€“ SQL Server

```bash
sqlcmd -S servidor -U usuario -P contraseÃ±a -Q "SELECT * FROM tabla"
```

#### ðŸ§  Casos de uso:
- Ejecutar consultas automatizadas desde scripts
- Validar integridad de datos en pipelines
- Exportar resultados con redirecciÃ³n de salida (`> salida.txt`)

---

## 6.2. CLIs de Cloud Providers (Ejemplos)

### `aws cli`

```bash
aws s3 ls
aws s3 cp archivo.csv s3://mi-bucket/
aws ec2 describe-instances
```

### `gcloud`

```bash
gcloud auth login
gcloud storage cp archivo.csv gs://mi-bucket/
gcloud compute instances list
```

### `az cli` (Azure)

```bash
az login
az storage blob upload --container-name datos --file archivo.csv --name archivo.csv
az vm list --output table
```

#### ðŸ§  Casos de uso:
- Automatizar cargas y descargas de datos
- Gestionar recursos cloud desde scripts
- IntegraciÃ³n con Airflow, Jenkins, CI/CD

---

## 6.3. InteracciÃ³n con Contenedores (Docker/Kubernetes)

### `docker`

```bash
docker ps
docker exec -it contenedor bash
docker cp archivo.txt contenedor:/ruta
```

### `kubectl`

```bash
kubectl get pods
kubectl logs nombre-pod
kubectl exec -it nombre-pod -- bash
kubectl cp archivo.txt pod:/ruta
```

#### ðŸ§  Casos de uso:
- Acceder a contenedores en ejecuciÃ³n
- Inspeccionar logs de ETL jobs o APIs
- Subir scripts o descargar resultados dentro del contenedor

---

## 6.4. Control de Versiones con Git

La lÃ­nea de comandos es el entorno mÃ¡s rÃ¡pido para interactuar con Git, especialmente para automatizar pushes, crear ramas o integrarlo con CI/CD.

```bash
git clone https://github.com/usuario/repositorio.git
cd repositorio
git checkout -b nueva-rama
git add archivo.py
git commit -m "Agrega script de validaciÃ³n"
git push origin nueva-rama
```

#### ðŸ§  Recomendaciones:
- Usar `git status` frecuentemente
- Integrar `git` en scripts para versionar backups o configuraciones

---

## 6.5. Lanzar Scripts de Python desde Bash

Python es el lenguaje preferido para procesamiento de datos. Bash puede lanzarlos, pasarles parÃ¡metros, capturar su salida, o integrarlos en pipelines mÃ¡s amplios.

### ðŸ“Œ Ejecutar scripts directamente:

```bash
python script.py
```

### ðŸ“Œ Activar entorno virtual:

```bash
source venv/bin/activate
python procesar_datos.py
deactivate
```

### ðŸ“Œ Ejecutar con logging y control de errores:

```bash
if python script.py > log.txt 2>&1; then
  echo "Ejecutado correctamente"
else
  echo "Error en ejecuciÃ³n"
fi
```

### ðŸ“Œ Pasar parÃ¡metros:

```bash
python etl.py --fecha 2025-04-19 --origen s3
```

---

# 7. TÃ³picos Adicionales y Buenas PrÃ¡cticas

AdemÃ¡s de los comandos y tÃ©cnicas clÃ¡sicas de Bash, existen herramientas complementarias y buenas prÃ¡cticas que marcan una gran diferencia en la productividad, robustez y mantenibilidad de scripts en Data Engineering.

---

## 7.1. GestiÃ³n de Variables de Entorno y Secretos

Las variables de entorno son fundamentales para mantener configuraciones desacopladas del cÃ³digo. TambiÃ©n se usan para manejar claves, rutas o parÃ¡metros en entornos de ejecuciÃ³n.

### ðŸ“Œ DefiniciÃ³n en Bash:

```bash
export DATA_PATH="/home/usuario/datos"
export API_KEY="mi_token_secreto"
```

### ðŸ“Œ Acceso en scripts:

```bash
echo "Ruta de datos: $DATA_PATH"
```

### ðŸ“Œ Uso de `.env` y `source`:

Guarda tus variables en un archivo `.env`:

```bash
# .env
API_KEY="mi_api_key"
```

Y cÃ¡rgalas con:

```bash
source .env
```

> âš ï¸ Nunca subas `.env` con secretos a Git. Usa `.gitignore`.

---

## 7.2. CompresiÃ³n y Archivado (`tar`, `gzip`, `zip`)

Estas herramientas permiten reducir el tamaÃ±o de archivos, comprimir backups o preparar envÃ­os de datos.

### `tar` â€“ Agrupar y archivar

```bash
tar -czvf backup.tar.gz carpeta/
tar -xvzf backup.tar.gz
```

### `gzip` â€“ Comprimir un solo archivo

```bash
gzip archivo.csv        # Genera archivo.csv.gz
gunzip archivo.csv.gz
```

### `zip` y `unzip` â€“ CompresiÃ³n multiplataforma

```bash
zip -r archivos.zip carpeta/
unzip archivos.zip
```

> ðŸ§  Ideal para ahorrar espacio y acelerar transferencias en pipelines.

---

## 7.3. ProgramaciÃ³n de Tareas con `cron`

`cron` permite ejecutar scripts automÃ¡ticamente en intervalos definidos (cada hora, dÃ­a, semana, etc.)

### ðŸ“Œ Ver y editar cronjobs:

```bash
crontab -e
```

### ðŸ“Œ Ejemplo de tarea diaria a las 2:00 AM:

```
0 2 * * * /home/usuario/scripts/etl.sh >> /home/usuario/logs/etl.log 2>&1
```

| Campo   | Significado         |
|---------|---------------------|
| `0`     | Minuto              |
| `2`     | Hora                |
| `*`     | DÃ­a del mes         |
| `*`     | Mes                 |
| `*`     | DÃ­a de la semana    |

### ðŸ“Œ Ver tareas programadas:

```bash
crontab -l
```

> ðŸ§  Perfecto para automatizar tareas ETL o backups.

---

## 7.4. Debugging de Scripts (`set -x`, `echo`)

### `set -x` â€“ Modo verbose

Muestra cada comando antes de ejecutarlo:

```bash
set -x
echo "Esto se verÃ¡ con su comando"
set +x
```

### `echo` para rastrear valores

```bash
echo "Procesando archivo: $archivo"
```

> âœ… Ãštil para entender errores, flujos lÃ³gicos y valores intermedios.

---

## 7.5. Estilo y Legibilidad en Scripts

Un script bien escrito no solo funciona, tambiÃ©n es fÃ¡cil de mantener y entender por otros.

### ðŸ§  Buenas prÃ¡cticas:

- Usa nombres descriptivos (`procesar_datos.sh` en lugar de `pd.sh`)
- AÃ±ade comentarios explicativos (`# Este bloque valida la conexiÃ³n`)
- Organiza en bloques lÃ³gicos (secciones de variables, funciones, ejecuciÃ³n)
- Usa `set -e` para evitar errores silenciosos
- Documenta al inicio el propÃ³sito y los argumentos del script

---

## 7.6. Herramientas CLI Ãºtiles para Data Engineers

MÃ¡s allÃ¡ de Bash puro, existen herramientas modernas que mejoran la experiencia y velocidad de trabajo:

| Herramienta | DescripciÃ³n |
|-------------|-------------|
| `htop`      | Monitor de sistema interactivo (CPU, RAM, procesos) |
| `watch`     | Repite un comando cada X segundos (`watch -n 5 df -h`) |
| `pv`        | Muestra progreso de datos por pipes (`cat archivo | pv | gzip > archivo.gz`) |
| `parallel`  | Ejecuta comandos en paralelo (`cat urls.txt | parallel wget`) |
| `fd`        | Alternativa moderna a `find` (mÃ¡s rÃ¡pida y fÃ¡cil de usar) |
| `ripgrep`   | BÃºsqueda rÃ¡pida de texto (mejor que `grep` para grandes proyectos) |

### ðŸ“Œ InstalaciÃ³n en Ubuntu:

```bash
sudo apt install htop pv moreutils fd-find ripgrep
```

---

# 8. Ejemplos de Scripts para Data Engineering

En esta secciÃ³n te presento tres ejemplos prÃ¡cticos y reales de cÃ³mo usar Bash para automatizar tareas comunes en el flujo de trabajo de un Data Engineer. Todos los scripts estÃ¡n diseÃ±ados para ser simples, reutilizables y fÃ¡ciles de adaptar.

---

## 8.1. Script para Descargar y Preprocesar Logs

Este script descarga un archivo de logs desde una URL, lo descomprime si es necesario, y filtra los errores mÃ¡s relevantes.

### ðŸ“ `descargar_y_filtrar_logs.sh`

```bash
#!/bin/bash

set -e

# Variables
URL_LOG="https://example.com/logs/app.log"
ARCHIVO="app.log"
SALIDA="errores_filtrados.log"

# Descargar
echo "Descargando logs desde $URL_LOG..."
curl -O "$URL_LOG"

# Validar descarga
if [ ! -f "$ARCHIVO" ]; then
    echo "Error: No se descargÃ³ el archivo."
    exit 1
fi

# Filtrar errores
echo "Filtrando errores..."
grep -i "ERROR" "$ARCHIVO" | grep -v "DEBUG" > "$SALIDA"

echo "Errores guardados en $SALIDA"
```

---

## 8.2. Script para Mover Datos Procesados a Almacenamiento Cloud

Este script toma un conjunto de archivos procesados y los sube a un bucket de AWS S3. TambiÃ©n permite loguear el proceso.

### ðŸ“ `subir_a_s3.sh`

```bash
#!/bin/bash

set -e
set -o pipefail

# Variables
CARPETA="datos_procesados"
BUCKET="s3://mi-bucket-etl/procesados/"
LOG="upload.log"

# Verificar AWS CLI
if ! command -v aws &> /dev/null; then
    echo "Error: aws cli no estÃ¡ instalado."
    exit 1
fi

# Subir archivos
echo "Subiendo datos desde $CARPETA a $BUCKET"
aws s3 cp "$CARPETA" "$BUCKET" --recursive | tee -a "$LOG"

echo "Subida completada. Revisa el log en $LOG"
```

---

## 8.3. Script Wrapper para Ejecutar un Proceso SQL/Python

Este script sirve como envoltorio (*wrapper*) que lanza primero una consulta SQL (ej. limpieza de staging) y luego un script de procesamiento en Python.

### ðŸ“ `ejecutar_pipeline.sh`

```bash
#!/bin/bash

set -e
set -o pipefail

# Variables
SQL_FILE="preparar_datos.sql"
PY_SCRIPT="procesar_datos.py"
LOG="pipeline.log"

# Ejecutar SQL
echo "[INFO] Ejecutando SQL..."
psql -U usuario -d basedatos -f "$SQL_FILE" >> "$LOG" 2>&1

# Validar salida SQL
if [ $? -ne 0 ]; then
    echo "[ERROR] FallÃ³ la consulta SQL"
    exit 1
fi

# Ejecutar Python
echo "[INFO] Ejecutando procesamiento Python..."
python "$PY_SCRIPT" >> "$LOG" 2>&1

if [ $? -eq 0 ]; then
    echo "[OK] Pipeline ejecutado correctamente"
else
    echo "[ERROR] FallÃ³ el script Python"
    exit 1
fi
```

---







